# 3-1.再起型ニューラルネットワークの概念

## RNN
時系列データに対応可能な、ニューラルネットワーク
## 時系列データ
時間的順序を追って一定間隔ごとに観察され，しかも相互に統計的依存関係が認められるようなデータの系列

## RNNの特徴
時系列モデルを扱うには、初期の状態と過去の時間t-1の状態を保持し、そこから次の時間でのtを再帰的に求める再帰構造が必要になる

## BPTT
・RNNにおいてのパラメータ調整方法の一種

# 3-2.LSTM

・RNNの課題時系列を遡れば遡るほど、勾配が消失していく
・勾配消失の解決方法とは、別で、構造自体を変えて解決したものがLSTM
・勾配消失問題とは？
・誤差逆伝播法が下位層に進んでいくに連れて、勾配がどんどん緩やかになっていく。そのため、勾配降下法による、更新では下位層のパラメータはほとんど変わらず、訓練は最適値に収束しなくなる。

# 3-3.GRU

・GRUとは？
・従来のLSTMでは、パラメータが多数存在していたため、計算負荷が大きかった。しかし、GRUでは、そのパラメータを大幅に削減し、精度は同等またはそれ以上が望める様になった構造。
・メリット計算負荷が低い

# 3-4.双方向RNN
・過去の情報だけでなく、未来の情報を加味することで、精度を向上させるためのモデル
・実用例文章の推敲や、機械翻訳等図式に利用される

# 3-5.Seq2Seq

Seq2seqとは?
・Encoder-Decoderモデルの一種を指す。
・Seq2seqの具体的な用途とは?
・機械対話や、機械翻訳などに使用されている
・Encoder RNNとは、ユーザーがインプットしたテキストデータを、単語等のトークンに区切って渡す構造。
・Taking :文章を単語等のトークン毎に分割し、トークンごとのIDに分割する
・Embedding :IDから、そのトークンを表す分散表現ベクトルに変換。
・Encoder RNN:ベクトルを順番にRNNに入力していく。
・Encoder RNN処理手順
・vec1をRNNに入力し、hidden stateを出力。このhiddenstateと次の入力vec2をまたRNNに入力してきたhidden stateを出力という流れを繰り返す。
・最後のvecを入れたときのhiddenstateをfinalstateとしてとっておく。
・このfinalstateがthoughtvectorと呼ばれ、入力した文の意味を表すベクトルとなる。

# 3-6.Word2vec

・課題:RNNでは、単語のような可変長の文字列をNNに与えることはできない。
・固定長形式で単語を表す必要がある。
・学習データからボキャブラリを作成※わかりやすく7語のボキャブラリを作成したら本来は、辞書の単語数だけできあがる。
・one-hot:ベクトルAppleｓを入力する場合は、入力層には以下のベクトルが入力される。※本来は、辞書の単語数だけone-hotベクトルができあがる。1...apples 0...eat 0...I 0...like 0...to
・メリットとして、大規模データの分散表現の学習が、現実的な計算速度とメモリ量で実現可能にした

# 3-7.Attention　Mechanism

・課題:seq2seq の問題は長い文章への対応が難しい

・seq2seq では、2単語でも、100単語でも、固定次元ベクトルの中に入力しなければならない。
・解決策:文章が長くなるほどそのシーケンスの内部表現の次元も大きくなっていく、仕組みが必要になる
・Attention　Mechanismとは、この課題を解決するべく「入力と出力のどの単語が関連しているのか」の関連度を学習する仕組みである



# 4-1.強化学習
* 強化学習とは、エージェントが長期的に報酬を最大化できる様に、環境の状況に合わせて行動を選択し、その行動によって環境が変化(報酬をエージェントに与える)するもの

* Ex.AlphaZero•自動車の自動運転等

# 4-2.AlphaGo
AlphaGoの学習は以下のステップで行われる
1. 教師あり学習によるRollOutPolicyとPolicyNetの学習
2. 強化学習によるPolicyNetの学習
3. 強化学習によるValueNetの学習

## PolicyNet（教師あり学習）
KGSの棋譜データから3000万局面分の訓練データを用意し、学習を行った.
具体的には、対局者が着手した手を1、残りを0とした19×19次元の配列を訓練データとし、それを分類問題として学習した.
この学習で作成したPolicyNetは57%ほどの精度である.

## ValueNet（強化学習）
現状のPolicyNetとPolicyPoolからランダムに選択されたPolicyNetと対局シミュレーションを行い、その結果を用いて方策勾配法で学習を行った.
PolicyPoolとは、PolicyNetの強化学習の過程を500Iteraionごとに記録し保存したものである.
現状のPolicyNet同士の対局ではなく、PolicyPoolに保存されているものとの対局を使用する理由は、過学習を防ぐ為.
この学習をminibatch size 128で1万回行った.

## AlphaGoとAlphaGoZeroの違い
* 教師あり学習を一切行わず、強化学習のみで作成した
* 特徴入力を石の配置のみにした
* PolicyNetとValueNetを１つのネットワークに統合した→デュアルネットワーク
* Residual Netを導入した
* モンテカルロ木探索からRollOutをなくした

# 4-3.高速化・軽量化技術
## 分散深層学習
分散深層学習とは、複数の計算資源（ワーカー）を使用し、並列的にニューラルネットを構築することで、効率の良い学習を行うことを指す.(深層学習は膨大なデータやパラメータ調整に多くの時間を要する為)
## 高速化
モデルが大きい時はモデル並列化を、データが大きい時はデータ並列化をすると良い.
### データ並列化
親モデルを各ワーカーに子モデルとしてコピーし、データを分割し、各ワーカーごとに計算させる.
### モデル並列化
親モデルを各ワーカーに分割し、それぞれのモデルを学習させる.全てのデータで学習が終わった後で、一つのモデルに復元する.

### GPU
CPUと違って、並列計算（特定の処理をいくつかの独立した小さな処理に細分化し、複数の処理装置上でそれぞれの処理を同時に行うこと）が得意.ニューラルネットの学習は単純な行列演算が多いので、高速化できる.
### GPGPU (General-purpose on GPU)
元々の使用目的であるグラフィック以外の用途で用いられるGPUの総称.

## 軽量化
### 量子化
重みの精度を下げることにより計算の高速化と省メモリ化を行う技術.

### 蒸留
複雑で精度の良い教師モデルから軽量な生徒モデルを効率よく学習を行う技術.

### プルーニング
寄与の少ないニューロンをモデルから削減し、高速化と省メモリ化を行う技術.

# 4-4.応用モデル

## MobileNet
* AlexNet以降、より深く・より複雑なCNNを構築することで精度を改善して来たが、計算量が増えることでコストがかかるデメリットがある
* MobileNetは、軽量で高速なCNN
* MobileNetはDepthwise ConvolutionとPointwise Convolutionの組み合わせで軽量化を実現


## DenseNet
* DenseNet(Dense Convolutional Network）は、CNNの一種.ResNetを改良したもの

* 全ての特徴量サイズが同じレイヤーを結合させて、スキップ接続を用いたもの

# 4-5.Transformer
* TransformerはRNNやCNNを使用せず、Attentionのみを用いるSeq2Seqモデル

* 主に自然言語処理 （NLP）の分野で使用される

* 時系列データを逐次処理する必要がない為、並列化が可能になり、訓練時間が短縮される



# 4-6.物体検知・セグメンテーション

* 物体検知とは、画像中から物体の位置の特定も含めてクラス分類を行う手法
* Ex.カメラの顔検出・自動運転の歩行者検知等
* セグメンテーションとは、画像に対してピクセルレベルでクラス分類を行う手法
* Ex.自動運転においての物体判別等
