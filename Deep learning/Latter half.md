3-1.再起型ニューラルネットワークの概念

・RNNとは、時系列データに対応可能な、ニューラルネットワーク
・時系列データとは、時間的順序を追って一定間隔ごとに観察され，しかも相互に統計的依存関係が認められるようなデータの系列

・RNNの特徴とは?
・時系列モデルを扱うには、初期の状態と過去の時間t-1の状態を保持し、そこから次の時間でのtを再帰的に求める再帰構造が必要になる

・BPTTとは？
・RNNにおいてのパラメータ調整方法の一種

3-2.LSTM

・RNNの課題時系列を遡れば遡るほど、勾配が消失していく
・勾配消失の解決方法とは、別で、構造自体を変えて解決したものがLSTM
・勾配消失問題とは？
・誤差逆伝播法が下位層に進んでいくに連れて、勾配がどんどん緩やかになっていく。そのため、勾配降下法による、更新では下位層のパラメータはほとんど変わらず、訓練は最適値に収束しなくなる。

3-3.GRU

・GRUとは？
・従来のLSTMでは、パラメータが多数存在していたため、計算負荷が大きかった。しかし、GRUでは、そのパラメータを大幅に削減し、精度は同等またはそれ以上が望める様になった構造。
・メリット計算負荷が低い

3-4.双方向RNN
・過去の情報だけでなく、未来の情報を加味することで、精度を向上させるためのモデル
・実用例文章の推敲や、機械翻訳等図式に利用される

3-5.Seq2Seq

Seq2seqとは?
・Encoder-Decoderモデルの一種を指す。
・Seq2seqの具体的な用途とは?
・機械対話や、機械翻訳などに使用されている
・Encoder RNNとは、ユーザーがインプットしたテキストデータを、単語等のトークンに区切って渡す構造。
・Taking :文章を単語等のトークン毎に分割し、トークンごとのIDに分割する
・Embedding :IDから、そのトークンを表す分散表現ベクトルに変換。
・Encoder RNN:ベクトルを順番にRNNに入力していく。
・Encoder RNN処理手順
・vec1をRNNに入力し、hidden stateを出力。このhiddenstateと次の入力vec2をまたRNNに入力してきたhidden stateを出力という流れを繰り返す。
・最後のvecを入れたときのhiddenstateをfinalstateとしてとっておく。
・このfinalstateがthoughtvectorと呼ばれ、入力した文の意味を表すベクトルとなる。

3-6.Word2vec

・課題:RNNでは、単語のような可変長の文字列をNNに与えることはできない。
・固定長形式で単語を表す必要がある。
・学習データからボキャブラリを作成※わかりやすく7語のボキャブラリを作成したら本来は、辞書の単語数だけできあがる。
・one-hot:ベクトルAppleｓを入力する場合は、入力層には以下のベクトルが入力される。※本来は、辞書の単語数だけone-hotベクトルができあがる。1...apples 0...eat 0...I 0...like 0...to
・メリットとして、大規模データの分散表現の学習が、現実的な計算速度とメモリ量で実現可能にした

3-7.Attention　Mechanism

・課題:seq2seq の問題は長い文章への対応が難しい
・seq2seq では、2単語でも、100単語でも、固定次元ベクトルの中に入力しなければならない。
・解決策:文章が長くなるほどそのシーケンスの内部表現の次元も大きくなっていく、仕組みが必要になる
・Attention　Mechanismとは、この課題を解決するべく「入力と出力のどの単語が関連しているのか」の関連度を学習する仕組みである



4-1.強化学習
強化学習とは、エージェントが長期的に報酬を最大化できる様に、環境の状況に合わせて行動を選択し、その行動によって環境が変化(報酬をエージェントに与える)するもの.

4-2.AlphaGo

AlphaGoの学習は以下のステップで行われる
１、教師あり学習によるRollOutPolicyとPolicyNetの学習
２、強化学習によるPolicyNetの学習
３、強化学習によるValueNetの学習
PolicyNetの教師あり学習
KGS Go Server（ネット囲碁対局サイト）の棋譜データから3000万局面分の教師を用意し、教師と同じ着手を予測できるよう学習を行った。
具体的には、教師が着手した手を1とし残りを0とした19×19次元の配列を教師とし、それを分類問題として学習した。
この学習で作成したPolicyNetは57%ほどの精度である。
PolicyNetの強化学習
現状のPolicyNetとPolicyPoolからランダムに選択されたPolicyNetと対局シミュレーションを行い、その結果を用いて方策勾配法で学習を行った。
PolicyPoolとは、PolicyNetの強化学習の過程を500Iteraionごとに記録し保存しておいたものである。
現状のPolicyNet同士の対局ではなく、PolicyPoolに保存されているものとの対局を使用する理由は、対局に幅を持たせて過学習を防ごうというのが主である。
この学習をminibatch size 128で1万回行った。
AlphaGo(Lee) とAlphaGoZeroの違い
１、教師あり学習を一切行わず、強化学習のみで作成
２、特徴入力からヒューリスティックな要素を排除し、石の配置のみにした
３、PolicyNetとValueNetを１つのネットワークに統合した
４、Residual Net（後述）を導入した
５、モンテカルロ木探索からRollOutシミュレーションをなくした

4-3.軽量化・高速化技術
・分散深層学習とは?
・深層学習は多くのデータを使用したり、パラメータ調整のために多くの時間を使用したりするため、高速な計算が求められる。
・複数の計算資源(ワーカー)を使用し、並列的にニューラルネットを構成することで、効率の良い学習を行いたい。
・データ並列化、モデル並列化、GPUによる高速技術は不可欠である。
・データ並列化:親モデルを各ワーカーに子モデルとしてコピーする。データを分割し、各ワーカーごとに計算させる。
・モデル並列化：親モデルを各ワーカーに分割し、それぞれのモデルを学習させる。全てのデータで学習が終わった後で、一つのモデルに復元。モデルが大きい時はモデル並列化を、データが大きい時はデータ並列化をすると良い。
・GPUによる高速化
・GPGPU (General-purpose on GPU)：元々の使用目的であるグラフィック以外の用途で使用されるGPUの総称
・GPUは、比較的低性能なコアが多数存在し、簡単な並列処理が得意である。ニューラルネットの学習は単純な行列演算が多いので、高速化が可能
・モデルの軽量化
・量子化：重みの精度を下げることにより計算の高速化と省メモリ化を行う技術
・蒸留：複雑で精度の良い教師モデルから軽量な生徒モデルを効率よく学習を行う技術
・プルーニング：寄与の少ないニューロンをモデルから削減し高速化と省メモリ化を行う技術

4-4.応用モデル

・MobileNets
・ディープラーニングモデルは精度は良いが、その分ネットワークが深くなり計算量が増える。
・計算量が増えると、多くの計算リソースが必要で、お金がかかってしまう。
・ディープラーニングモデルの軽量化・高速化・高精度化を実現
・一般的な畳み込みレイヤーは計算量が多い
・MobileNetsはDepthwise ConvolutionとPointwise Convolutionの組み合わせで軽量化を実現
・DenseNet
・Dense Convolutional Network（以下、DenseNet）は、畳込みニューラルネットワーク（以下、CNN）アーキテクチャの一種である。
・ニューラルネットワークでは層が深くなるにつれて、学習が難しくなるという問題があったが、Residual Network（以下、ResNet）などのCNNアーキテクチャでは前方の層から後方の層へアイデンティティ接続を介してパスを作ることで問題を対処した。
・DenseBlockと呼ばれるモジュールを用いた、DenseNetもそのようなアーキテクチャの一つである。

4-5.Transformer
・TransformerはRNNやCNNを使用せず、Attentionのみを用いるSeq2Seqモデルです。
・並列計算が可能なためRNNに比べて計算が高速な上、Self-Attentionと呼ばれる機構を用いることにより、局所的な位置しか参照できないCNNと異なり、系列内の任意の位置の情報を参照することを可能にしています。
・その他にもいくつかの工夫が加えられており、翻訳に限らない自然言語処理のあらゆるタスクで圧倒的な性能を示すことが知られています。
・TransformerのモデルもEncoder-Decoderモデルの構造になっています。 EncoderとDecoderはPositional Encoding: 入出力の単語のEmbedding時に単語の位置情報を埋め込む、Scaled Dot-Product Attention: 内積でAttentionを計算し、スケーリングを行う、Multi-head Attention: Scaled Dot-Product Attentionを複数のヘッドで並列化する、Position-Wise Feed Forward Network: 単語列の位置ごとに独立して処理を行う など、いくつかのモジュールから構成されているため、それぞれのモジュールを個別に定義していきます。

4-6.物体検知・セグメンテーション

・物体検知とは、画像を取り込み、画像の中から定められた物体の位置と種類、個数を特定する技術である
・また、単純な分類問題と比較すると、物体の位置についても注目している点が異なる
・物体検出で利用される代表的なデータセットは以下
・VOC12,ILSVRC17,MS CICI18,OICOD18
・物体検知は、外観検査によく使われており、幅広い分野で活躍している
・物体検出にはいくつかの手法がある